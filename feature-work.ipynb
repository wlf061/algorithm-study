{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#========================================数据预处理=============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.标准化：标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布； \n",
    " 使得每个属性的所有数据聚集在0 附近，方差为1\n",
    "\n",
    "##sklearn 的实现方式 x'= （x-均值）/标准差\n",
    "## 有两种实现方式:直接通过scale函数进行转化; 使用StandarScaler类，\n",
    "使用该类的好处在于可以保存训练集中的参数（均值，方差）直接使用其对象转换测试集数据\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487, -1.22474487],\n",
       "       [ 1.22474487,  0.        ,  1.22474487],\n",
       "       [-1.22474487,  1.22474487,  0.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##使用scale 类直接进行转化\n",
    "X = np.array([[1.,-1.,-2.],\n",
    "              [2.,0.,0.],\n",
    "              [0.,1.,-1.]])\n",
    "X_scaled = preprocessing.scale(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.mean(axis=0) ###计算每一列的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###standardScaler 类\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0., -1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.66666667, 0.66666667])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487, -1.22474487],\n",
       "       [ 1.22474487,  0.        ,  1.22474487],\n",
       "       [-1.22474487,  1.22474487,  0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n2.区间缩放：将属性缩放到一个指定的最大值和最小值（通常是1-0）之间，可以通过preprocessing.MinxMaxScaler类来实现\\n实现为：x' = (x-Min)/(Max-Min)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "2.区间缩放或者归一化：将属性缩放到一个指定的最大值和最小值（通常是1-0）之间，可以通过preprocessing.MinxMaxScaler类来实现\n",
    "实现为：x' = (x-Min)/(Max-Min)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= np.array([[1.,-1.,-2.],\n",
    "              [2.,0.,0.],\n",
    "              [0.,1.,-1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0. , 0. ],\n",
       "       [1. , 0.5, 1. ],\n",
       "       [0. , 1. , 0.5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. 不要中心化稀疏数据，引入正则化：\\n    正则化的过程是将每个样本缩放到单位范数（每个样本的范数为1），\\n    其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. 不要中心化稀疏数据，引入正则化：\n",
    "    正则化的过程是将每个样本缩放到单位范数（每个样本的范数为1），\n",
    "    其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准\n",
    "    参考链接：https://www.cnblogs.com/chaosimple/p/4153167.html\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829, -0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1.,-1.,-2.],\n",
    "              [2.,0.,0.],\n",
    "              [0.,1.,-1.]])\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "导入 iris 数据, 做后面实验数据\n",
    "\"\"\"\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 0., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "4. 定量特征二值化：特征二值化的核心在于设定一个阈值， 大于阈值的赋值为1， 小于等于阈值的赋值为0\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import Binarizer\n",
    "Binarizer(threshold=3).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5. 定性特征编码: 这里使用sklearn 的OneHotEncoder\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = iris.target.reshape((-1,1))\n",
    "model = OneHotEncoder(sparse=False)  \n",
    "model.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(data_train)  ####如果sparse 设置为True ，最后的结果需要用model.transform(data_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. 缺失值计算:Imputer 类提供了估算缺失值的基本策略，使用缺失值所在的行/列中的平均值、中位数或者众数来填充\n",
    "strategy: mean 平均值； \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array([[1, 2], [np.nan, 3], [7, 6]])\n",
    "test_data =  np.array([[np.nan, 2], [6, np.nan], [7, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###strategy 为mean, axis 为0\n",
    "imp = Imputer(missing_values='NaN',strategy='mean',axis=0)\n",
    "imp.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.        , 2.        ],\n",
       "       [6.        , 3.66666667],\n",
       "       [7.        , 6.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.        , 3.66666667])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###验证，计算 axis 为0 即列 的均值\n",
    "np.nanmean(imp_data,axis=0)  ###通过numpy 得到的 均值 即为模型的均值，填充到test_data中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "7. 数据变换：多项式变换PolynomialFeatures, 对数变换等\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(6).reshape(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###PolynomialFeatures 默认为2维， 这里将（X1,X2) 转化成 (1, X_1, X_2, X_1^2, X_1X_2, X_2^2)\n",
    "## 参数interaction_only  默认为false, 是否只需要正交项。\n",
    "## 如果 设置为true, 这里的转换是（X1,X2) 转化成 (1, X_1, X_2,X_1X_2)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.80828877, 1.5040774 , 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.38629436, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.7227666 , 1.41098697, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5260563 , 0.87546874, 0.18232156],\n",
       "       [1.85629799, 1.58923521, 0.99325177, 0.33647224],\n",
       "       [1.7227666 , 1.48160454, 0.87546874, 0.26236426],\n",
       "       [1.79175947, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.68639895, 1.36097655, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.09531018],\n",
       "       [1.85629799, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.75785792, 1.48160454, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.09531018],\n",
       "       [1.66770682, 1.38629436, 0.74193734, 0.09531018],\n",
       "       [1.91692261, 1.60943791, 0.78845736, 0.18232156],\n",
       "       [1.90210753, 1.68639895, 0.91629073, 0.33647224],\n",
       "       [1.85629799, 1.58923521, 0.83290912, 0.33647224],\n",
       "       [1.80828877, 1.5040774 , 0.87546874, 0.26236426],\n",
       "       [1.90210753, 1.56861592, 0.99325177, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.91629073, 0.26236426],\n",
       "       [1.85629799, 1.48160454, 0.99325177, 0.18232156],\n",
       "       [1.80828877, 1.54756251, 0.91629073, 0.33647224],\n",
       "       [1.7227666 , 1.5260563 , 0.69314718, 0.18232156],\n",
       "       [1.80828877, 1.45861502, 0.99325177, 0.40546511],\n",
       "       [1.75785792, 1.48160454, 1.06471074, 0.18232156],\n",
       "       [1.79175947, 1.38629436, 0.95551145, 0.18232156],\n",
       "       [1.79175947, 1.48160454, 0.95551145, 0.33647224],\n",
       "       [1.82454929, 1.5040774 , 0.91629073, 0.18232156],\n",
       "       [1.82454929, 1.48160454, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.41098697, 0.95551145, 0.18232156],\n",
       "       [1.85629799, 1.48160454, 0.91629073, 0.33647224],\n",
       "       [1.82454929, 1.62924054, 0.91629073, 0.09531018],\n",
       "       [1.87180218, 1.64865863, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.09531018],\n",
       "       [1.79175947, 1.43508453, 0.78845736, 0.18232156],\n",
       "       [1.87180218, 1.5040774 , 0.83290912, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.09531018],\n",
       "       [1.68639895, 1.38629436, 0.83290912, 0.18232156],\n",
       "       [1.80828877, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.83290912, 0.26236426],\n",
       "       [1.70474809, 1.19392247, 0.83290912, 0.26236426],\n",
       "       [1.68639895, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.95551145, 0.47000363],\n",
       "       [1.80828877, 1.56861592, 1.06471074, 0.33647224],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.95551145, 0.18232156],\n",
       "       [1.7227666 , 1.43508453, 0.87546874, 0.18232156],\n",
       "       [1.84054963, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.45861502, 0.87546874, 0.18232156],\n",
       "       [2.07944154, 1.43508453, 1.74046617, 0.87546874],\n",
       "       [2.00148   , 1.43508453, 1.70474809, 0.91629073],\n",
       "       [2.06686276, 1.41098697, 1.77495235, 0.91629073],\n",
       "       [1.87180218, 1.19392247, 1.60943791, 0.83290912],\n",
       "       [2.01490302, 1.33500107, 1.7227666 , 0.91629073],\n",
       "       [1.90210753, 1.33500107, 1.70474809, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.74046617, 0.95551145],\n",
       "       [1.77495235, 1.22377543, 1.45861502, 0.69314718],\n",
       "       [2.02814825, 1.36097655, 1.7227666 , 0.83290912],\n",
       "       [1.82454929, 1.30833282, 1.58923521, 0.87546874],\n",
       "       [1.79175947, 1.09861229, 1.5040774 , 0.69314718],\n",
       "       [1.93152141, 1.38629436, 1.64865863, 0.91629073],\n",
       "       [1.94591015, 1.16315081, 1.60943791, 0.69314718],\n",
       "       [1.96009478, 1.36097655, 1.74046617, 0.87546874],\n",
       "       [1.88706965, 1.36097655, 1.5260563 , 0.83290912],\n",
       "       [2.04122033, 1.41098697, 1.68639895, 0.87546874],\n",
       "       [1.88706965, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.91692261, 1.30833282, 1.62924054, 0.69314718],\n",
       "       [1.97408103, 1.16315081, 1.70474809, 0.91629073],\n",
       "       [1.88706965, 1.25276297, 1.58923521, 0.74193734],\n",
       "       [1.93152141, 1.43508453, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.33500107, 1.60943791, 0.83290912],\n",
       "       [1.98787435, 1.25276297, 1.77495235, 0.91629073],\n",
       "       [1.96009478, 1.33500107, 1.74046617, 0.78845736],\n",
       "       [2.00148   , 1.36097655, 1.66770682, 0.83290912],\n",
       "       [2.02814825, 1.38629436, 1.68639895, 0.87546874],\n",
       "       [2.05412373, 1.33500107, 1.75785792, 0.87546874],\n",
       "       [2.04122033, 1.38629436, 1.79175947, 0.99325177],\n",
       "       [1.94591015, 1.36097655, 1.70474809, 0.91629073],\n",
       "       [1.90210753, 1.28093385, 1.5040774 , 0.69314718],\n",
       "       [1.87180218, 1.22377543, 1.56861592, 0.74193734],\n",
       "       [1.87180218, 1.22377543, 1.54756251, 0.69314718],\n",
       "       [1.91692261, 1.30833282, 1.58923521, 0.78845736],\n",
       "       [1.94591015, 1.30833282, 1.80828877, 0.95551145],\n",
       "       [1.85629799, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.94591015, 1.48160454, 1.70474809, 0.95551145],\n",
       "       [2.04122033, 1.41098697, 1.74046617, 0.91629073],\n",
       "       [1.98787435, 1.19392247, 1.68639895, 0.83290912],\n",
       "       [1.88706965, 1.38629436, 1.62924054, 0.83290912],\n",
       "       [1.87180218, 1.25276297, 1.60943791, 0.83290912],\n",
       "       [1.87180218, 1.28093385, 1.68639895, 0.78845736],\n",
       "       [1.96009478, 1.38629436, 1.7227666 , 0.87546874],\n",
       "       [1.91692261, 1.28093385, 1.60943791, 0.78845736],\n",
       "       [1.79175947, 1.19392247, 1.45861502, 0.69314718],\n",
       "       [1.88706965, 1.30833282, 1.64865863, 0.83290912],\n",
       "       [1.90210753, 1.38629436, 1.64865863, 0.78845736],\n",
       "       [1.90210753, 1.36097655, 1.64865863, 0.83290912],\n",
       "       [1.97408103, 1.36097655, 1.66770682, 0.83290912],\n",
       "       [1.80828877, 1.25276297, 1.38629436, 0.74193734],\n",
       "       [1.90210753, 1.33500107, 1.62924054, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.94591015, 1.25276297],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.09186406, 1.38629436, 1.93152141, 1.13140211],\n",
       "       [1.98787435, 1.36097655, 1.88706965, 1.02961942],\n",
       "       [2.01490302, 1.38629436, 1.91692261, 1.16315081],\n",
       "       [2.1517622 , 1.38629436, 2.02814825, 1.13140211],\n",
       "       [1.77495235, 1.25276297, 1.70474809, 0.99325177],\n",
       "       [2.11625551, 1.36097655, 1.98787435, 1.02961942],\n",
       "       [2.04122033, 1.25276297, 1.91692261, 1.02961942],\n",
       "       [2.10413415, 1.5260563 , 1.96009478, 1.25276297],\n",
       "       [2.01490302, 1.43508453, 1.80828877, 1.09861229],\n",
       "       [2.00148   , 1.30833282, 1.84054963, 1.06471074],\n",
       "       [2.05412373, 1.38629436, 1.87180218, 1.13140211],\n",
       "       [1.90210753, 1.25276297, 1.79175947, 1.09861229],\n",
       "       [1.91692261, 1.33500107, 1.80828877, 1.22377543],\n",
       "       [2.00148   , 1.43508453, 1.84054963, 1.19392247],\n",
       "       [2.01490302, 1.38629436, 1.87180218, 1.02961942],\n",
       "       [2.16332303, 1.56861592, 2.04122033, 1.16315081],\n",
       "       [2.16332303, 1.28093385, 2.06686276, 1.19392247],\n",
       "       [1.94591015, 1.16315081, 1.79175947, 0.91629073],\n",
       "       [2.06686276, 1.43508453, 1.90210753, 1.19392247],\n",
       "       [1.88706965, 1.33500107, 1.77495235, 1.09861229],\n",
       "       [2.16332303, 1.33500107, 2.04122033, 1.09861229],\n",
       "       [1.98787435, 1.30833282, 1.77495235, 1.02961942],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.13140211],\n",
       "       [2.10413415, 1.43508453, 1.94591015, 1.02961942],\n",
       "       [1.97408103, 1.33500107, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.38629436, 1.77495235, 1.02961942],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.13140211],\n",
       "       [2.10413415, 1.38629436, 1.91692261, 0.95551145],\n",
       "       [2.12823171, 1.33500107, 1.96009478, 1.06471074],\n",
       "       [2.18605128, 1.56861592, 2.00148   , 1.09861229],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.16315081],\n",
       "       [1.98787435, 1.33500107, 1.80828877, 0.91629073],\n",
       "       [1.96009478, 1.28093385, 1.88706965, 0.87546874],\n",
       "       [2.16332303, 1.38629436, 1.96009478, 1.19392247],\n",
       "       [1.98787435, 1.48160454, 1.88706965, 1.22377543],\n",
       "       [2.00148   , 1.41098697, 1.87180218, 1.02961942],\n",
       "       [1.94591015, 1.38629436, 1.75785792, 1.02961942],\n",
       "       [2.06686276, 1.41098697, 1.85629799, 1.13140211],\n",
       "       [2.04122033, 1.41098697, 1.88706965, 1.22377543],\n",
       "       [2.06686276, 1.41098697, 1.80828877, 1.19392247],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.05412373, 1.43508453, 1.93152141, 1.19392247],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.25276297],\n",
       "       [2.04122033, 1.38629436, 1.82454929, 1.19392247],\n",
       "       [1.98787435, 1.25276297, 1.79175947, 1.06471074],\n",
       "       [2.01490302, 1.38629436, 1.82454929, 1.09861229],\n",
       "       [1.97408103, 1.48160454, 1.85629799, 1.19392247],\n",
       "       [1.93152141, 1.38629436, 1.80828877, 1.02961942]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "8. 自定义转换器：FunctionTransformer\n",
    "\"\"\"\n",
    "from numpy import log1p\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "FunctionTransformer(log1p).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================特征选择======================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.Filter: 方差选择法； 相关系数法；卡方检验；互信息法\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "方差选择法：使用sklearn 中的VarianceThreshold\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.1],\n",
       "       [1.2],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1.7],\n",
       "       [1.9],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.2],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.6],\n",
       "       [1.9],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [4.7],\n",
       "       [4.5],\n",
       "       [4.9],\n",
       "       [4. ],\n",
       "       [4.6],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [3.3],\n",
       "       [4.6],\n",
       "       [3.9],\n",
       "       [3.5],\n",
       "       [4.2],\n",
       "       [4. ],\n",
       "       [4.7],\n",
       "       [3.6],\n",
       "       [4.4],\n",
       "       [4.5],\n",
       "       [4.1],\n",
       "       [4.5],\n",
       "       [3.9],\n",
       "       [4.8],\n",
       "       [4. ],\n",
       "       [4.9],\n",
       "       [4.7],\n",
       "       [4.3],\n",
       "       [4.4],\n",
       "       [4.8],\n",
       "       [5. ],\n",
       "       [4.5],\n",
       "       [3.5],\n",
       "       [3.8],\n",
       "       [3.7],\n",
       "       [3.9],\n",
       "       [5.1],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [4.4],\n",
       "       [4.1],\n",
       "       [4. ],\n",
       "       [4.4],\n",
       "       [4.6],\n",
       "       [4. ],\n",
       "       [3.3],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.3],\n",
       "       [3. ],\n",
       "       [4.1],\n",
       "       [6. ],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.6],\n",
       "       [4.5],\n",
       "       [6.3],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [5. ],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [6.7],\n",
       "       [6.9],\n",
       "       [5. ],\n",
       "       [5.7],\n",
       "       [4.9],\n",
       "       [6.7],\n",
       "       [4.9],\n",
       "       [5.7],\n",
       "       [6. ],\n",
       "       [4.8],\n",
       "       [4.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [6.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.6],\n",
       "       [6.1],\n",
       "       [5.6],\n",
       "       [5.5],\n",
       "       [4.8],\n",
       "       [5.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.7],\n",
       "       [5.2],\n",
       "       [5. ],\n",
       "       [5.2],\n",
       "       [5.4],\n",
       "       [5.1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "VarianceThreshold(threshold=3).fit_transform(iris.data) ##只保留了一列的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "相关系数法：先要计算各个特征对目标值的相关系数以及相关系数的p值\n",
    "用feature_selection 库的SelectKBest 类结合相关系数来选择特征\n",
    "\"\"\"\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower noise (0.6538711966537304, 5.626422851812266e-38)\n",
      "Higher noise (-0.037955664785317346, 0.5125302408761676)\n"
     ]
    }
   ],
   "source": [
    "###输出结果为（score, p-value）,当噪音比较小的时候，相关性很强，p-value很低\n",
    "from scipy.stats import pearsonr\n",
    "size=300\n",
    "x = np.random.normal(0,1,size)\n",
    "print(\"Lower noise\", pearsonr(x, x + np.random.normal(0, 1, size)))\n",
    "print(\"Higher noise\", pearsonr(x, x + np.random.normal(0, 10, size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "卡方检验：\n",
    "\"\"\"\n",
    "from sklearn.feature_selection import chi2\n",
    "X,y = iris.data, iris.target\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=2).fit_transform(X,y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n互信息和最大信息系数：\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "互信息和最大信息系数：\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "递归特征消除法：sklearn 中的RFE来实现\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "iris = load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "svc = SVC(kernel=\"linear\", C=1)\n",
    "rfe = RFE(estimator=svc, n_features_to_select=2, step=1)\n",
    "rfe.fit(x, y)\n",
    "ranking = rfe.ranking_\n",
    "ranking\n",
    "# [3 2 1 1] 说明第三维度特征和第四维度特征排名前2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用逻辑回归\n",
    "ref2 = RFE(estimator=LogisticRegression(), n_features_to_select=2).fit(iris.data, iris.target)\n",
    "ref2.ranking_\n",
    "# [3 1 2 1]  这里则选择认为第二维和第四维特征重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Embedded: sklearn 使用SelectFromModel\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "基于L1 的特征选择:常用可以用的模型有\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 例子，这里用支持向量机了 ---\n",
    "### 这里LinearSVC 里面的penatly 设置成了l1,SelectFromModel 对应的threshold 为1e-5\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape\n",
    "# (150, 4)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X,y)  # 这里的惩罚项是L1,别看做是11，这里L是小写\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape ##丢弃了一个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "基于树模型的特征选择：GBDT 和 RF\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    " \n",
    "#GBDT作为基模型的特征选择\n",
    "X_new = SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2.0,
    "version_minor": 0.0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
